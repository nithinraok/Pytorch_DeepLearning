{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/RNN_LSTM/AnnaKariennaNovel/anna.txt','r') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985223"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=set(text)\n",
    "int2char = {i:ch for i,ch in enumerate(chars)}\n",
    "char2int = {ch:i for i,ch in enumerate(chars)}\n",
    "\n",
    "encoded=np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1985223,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, 25, 50, 14, 41, 15, 75, 33, 80, 32, 32, 32,  9, 50, 14, 14, 57,\n",
       "       33,  6, 50, 16, 28,  5, 28, 15, 13, 33, 50, 75, 15, 33, 50,  5,  5,\n",
       "       33, 50,  5, 28, 72, 15, 37, 33, 15, 52, 15, 75, 57, 33, 20, 46, 25,\n",
       "       50, 14, 14, 57, 33,  6, 50, 16, 28,  5, 57, 33, 28, 13, 33, 20, 46,\n",
       "       25, 50, 14, 14, 57, 33, 28, 46, 33, 28, 41, 13, 33, 29, 54, 46, 32,\n",
       "       54, 50, 57, 58, 32, 32,  4, 52, 15, 75, 57, 41, 25, 28, 46])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120919da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(encoded);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(int2char[k] for k in encoded[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    one_hot= np.zeros((np.multiply(*arr.shape),n_labels),dtype=np.float32)\n",
    "    \n",
    "    one_hot[np.arange(one_hot.shape[0]),arr.flatten()]=1.\n",
    "    \n",
    "    one_hot=one_hot.reshape((*arr.shape,n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "test_seq=np.array([[3,5,1]])\n",
    "one_hot=one_hot_encode(test_seq,8)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr,batch_size,seq_length):\n",
    "    \n",
    "    batch_size_total=batch_size*seq_length\n",
    "    n_batches=len(arr)//batch_size_total\n",
    "    \n",
    "    arr=arr[:n_batches*batch_size_total]\n",
    "    arr=arr.reshape((batch_size,-1))\n",
    "    \n",
    "    for n in range(0,arr.shape[1],seq_length):\n",
    "        x=arr[:,n:n+seq_length]\n",
    "        \n",
    "        y=np.zeros_like(x)\n",
    "        try:\n",
    "            y[:,:-1],y[:,-1]=x[:,1:], arr[:,n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:,:-1],y[:,-1]=x[:,1:], arr[:,0]\n",
    "        \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=get_batches(encoded,8,50)\n",
    "x,y=next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 50)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 25, 50, 14, 41, 15, 75, 33, 80, 32, 32, 32],\n",
       "       [13, 29, 46, 33, 41, 25, 50, 41, 33, 50, 41, 41],\n",
       "       [15, 46, 27, 33, 29, 75, 33, 50, 33,  6, 29, 15],\n",
       "       [13, 33, 41, 25, 15, 33, 73, 25, 28, 15,  6, 33],\n",
       "       [33, 13, 50, 54, 33, 25, 15, 75, 33, 41, 15, 50],\n",
       "       [73, 20, 13, 13, 28, 29, 46, 33, 50, 46, 27, 33],\n",
       "       [33, 51, 46, 46, 50, 33, 25, 50, 27, 33, 13, 50],\n",
       "       [74, 70,  5, 29, 46, 13, 72, 57, 58, 33, 49, 79]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:10,:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25, 50, 14, 41, 15, 75, 33, 80, 32, 32],\n",
       "       [29, 46, 33, 41, 25, 50, 41, 33, 50, 41],\n",
       "       [46, 27, 33, 29, 75, 33, 50, 33,  6, 29],\n",
       "       [33, 41, 25, 15, 33, 73, 25, 28, 15,  6],\n",
       "       [13, 50, 54, 33, 25, 15, 75, 33, 41, 15],\n",
       "       [20, 13, 13, 28, 29, 46, 33, 50, 46, 27],\n",
       "       [51, 46, 46, 50, 33, 25, 50, 27, 33, 13],\n",
       "       [70,  5, 29, 46, 13, 72, 57, 58, 33, 49]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print(\"Training on GPU\")\n",
    "else:\n",
    "    print(\"Training on CPU\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self,tokens, n_hidden=256, n_layers=2,\n",
    "                drop_prob=0.5,lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob=drop_prob\n",
    "        self.n_layers=n_layers\n",
    "        self.n_hidden=n_hidden\n",
    "        self.lr=lr\n",
    "        \n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch : ii for ii,ch in self.int2char.items()}\n",
    "        \n",
    "        self.LSTM = nn.LSTM(input_size=len(self.chars),hidden_size=self.n_hidden,\n",
    "                           num_layers=self.n_layers,batch_first=True,\n",
    "                           dropout=drop_prob)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(n_hidden,len(self.chars))\n",
    "\n",
    "    def forward(self,x,hidden):\n",
    "        \n",
    "        r_output,hidden=self.LSTM(x,hidden)\n",
    "        out=self.dropout(r_output)\n",
    "        \n",
    "        out=out.contiguous().view(-1,self.n_hidden)\n",
    "        out=self.fc(out)\n",
    "        \n",
    "        return out,hidden\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
    "    ''' Training a network \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        net: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
    "        seq_length: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "    \n",
    "    '''\n",
    "    net.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    val_idx = int(len(data)*(1-val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "            \n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            if(train_on_gpu):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output, val_h = net(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
    "                \n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                net.train() # reset to train mode after iterationg through validation data\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (LSTM): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_hidden=512\n",
    "n_layers=2\n",
    "\n",
    "model=CharRNN(chars,n_hidden=n_hidden,n_layers=n_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Step: 10... Loss: 3.1495... Val Loss: 3.1204\n",
      "Epoch: 1/20... Step: 20... Loss: 3.1049... Val Loss: 3.1154\n",
      "Epoch: 1/20... Step: 30... Loss: 3.1098... Val Loss: 3.1053\n",
      "Epoch: 1/20... Step: 40... Loss: 5.5461... Val Loss: 3.1724\n",
      "Epoch: 1/20... Step: 50... Loss: 3.1056... Val Loss: 3.0904\n",
      "Epoch: 1/20... Step: 60... Loss: 3.0547... Val Loss: 3.0509\n",
      "Epoch: 1/20... Step: 70... Loss: 2.9821... Val Loss: 2.9749\n",
      "Epoch: 1/20... Step: 80... Loss: 2.9022... Val Loss: 2.8888\n",
      "Epoch: 1/20... Step: 90... Loss: 2.7843... Val Loss: 2.7760\n",
      "Epoch: 1/20... Step: 100... Loss: 2.6885... Val Loss: 2.6424\n",
      "Epoch: 1/20... Step: 110... Loss: 2.6003... Val Loss: 2.5729\n",
      "Epoch: 1/20... Step: 120... Loss: 2.5410... Val Loss: 2.5209\n",
      "Epoch: 1/20... Step: 130... Loss: 2.5233... Val Loss: 2.4787\n",
      "Epoch: 2/20... Step: 140... Loss: 2.4783... Val Loss: 2.4403\n",
      "Epoch: 2/20... Step: 150... Loss: 2.4469... Val Loss: 2.4137\n",
      "Epoch: 2/20... Step: 160... Loss: 2.4171... Val Loss: 2.3801\n",
      "Epoch: 2/20... Step: 170... Loss: 2.3648... Val Loss: 2.3548\n",
      "Epoch: 2/20... Step: 180... Loss: 2.3418... Val Loss: 2.3329\n",
      "Epoch: 2/20... Step: 190... Loss: 2.2955... Val Loss: 2.3022\n",
      "Epoch: 2/20... Step: 200... Loss: 2.2987... Val Loss: 2.2799\n",
      "Epoch: 2/20... Step: 210... Loss: 2.2761... Val Loss: 2.2621\n",
      "Epoch: 2/20... Step: 220... Loss: 2.2326... Val Loss: 2.2315\n",
      "Epoch: 2/20... Step: 230... Loss: 2.2409... Val Loss: 2.2201\n",
      "Epoch: 2/20... Step: 240... Loss: 2.2189... Val Loss: 2.1913\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-678e0d9d642f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-86ed5707e05b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data, epochs, batch_size, seq_length, lr, clip, val_frac, print_every)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# get the output from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-d5b47c150e7c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mr_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mcy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforgetgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mingate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "seq_length=100\n",
    "\n",
    "n_epochs=20\n",
    "\n",
    "train(model,data=encoded,epochs=n_epochs,batch_size=batch_size,seq_length=seq_length,lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, char, h=None, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        \n",
    "        # tensor inputs\n",
    "        x = np.array([[net.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(net.chars))\n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = net(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "        \n",
    "        # get top characters\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(net.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return net.int2char[char], h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample(net, size, prime='The', top_k=None):\n",
    "        \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "    \n",
    "    net.eval() # eval mode\n",
    "    \n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = net.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annatisile the wherd thet of\n",
      "the thith wand she solted, and to the torly to horsing on what hit andat he soun hid sishisgered ancoret has some soudstiste afdesterithy.\"\n",
      "\n",
      "That wing hed so to gount whre was thetere wat thet tound ontthit woring the wad and andederen te hit southe the sadtiting thet houds, thet\n",
      "wong ontit hound.\n",
      "\n",
      "I has as wothin wes her and oushy shouns to\n",
      "he tat ant tho se thaned hed was thas.\n",
      "\"\" ote an with, and there to her homer ound on the well and the then thens onttey of the part ont the gad thas\n",
      "hits thing with the thet of\n",
      "onte ater onge hars thit worle then shith al teres tele to to shas ant an and of the wered, her serand tot hith this he with had he wele was the chong serting werled on thens and oushen aly ofthis wond atery him whe han ang ald ot the ghe sisted, thas hing ther tho se soud to and than he cand and\n",
      "sor hy with tall to\n",
      "hind.\"\n",
      "\n",
      "Antely\n",
      "Anthe casting atte sititis oftaring tised\n",
      "ot and her hed soutell, sherisgeded hes thime thenst of thit he tho catere alla\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, 1000, prime='Anna', top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
